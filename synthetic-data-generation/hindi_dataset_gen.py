# -*- coding: utf-8 -*-
"""Hindi_dataset_gen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18s-OT1ZKZhHFaXMoP4B-A8TWB1jdgcuH
"""

import os
import random
import cv2
import pandas as pd
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont,ImageOps
import time

import random
from PIL import Image, ImageDraw, ImageFont

import re
import random
from wordfreq import top_n_list


from PIL import Image, ImageEnhance, ImageFilter
import random
import io
import os
pure_numbers = [str(random.randint(100, 999999)) for _ in range(5000)]
# Get top 5000 words in English (more than needed)
top_words = top_n_list('hi', 100000)

# Filter to words with length > 5
filtered_words = [word for word in top_words if len(word) >=5]

# Get top 1000
hindi_words = filtered_words[:4000]

mix_base_words = filtered_words[4000:4500]
mixed_words_hindi = []
for word in mix_base_words:
    number = str(random.randint(10, 9999))
    if random.random() < 0.5:
        mixed_words_hindi.append(word + " " + number)
    else:
        mixed_words_hindi.append(number + " " + word)

# Step 4: Generate 10k pure numbers
  #10% of data

hindi_words += mixed_words_hindi + pure_numbers

# Step 1: Load and filter English words (length > 5)
all_words = top_n_list('en', 1000000)
filtered_words = [word for word in all_words if len(word) > 5]
random.shuffle(filtered_words)  # Shuffle at the start to randomize selection

# Step 2: Slice unique segments for each type
lower_words = filtered_words[:2500] #50% of data
upper_words = [word.upper() for word in filtered_words[2500:3000]] #10% of data
capitalized_words = [word.capitalize() for word in filtered_words[3000:4000]] #20% 0f data
mix_base_words = filtered_words[4000:4500] #num+words 10%of data

# Step 3: Create 10k mixed word+number entries
mixed_words_english = []
for word in mix_base_words:
    number = str(random.randint(10, 9999))
    if random.random() < 0.5:
        mixed_words_english.append(word + " " + number)
    else:
        mixed_words_english.append(number + " " + word)

# Step 4: Generate 10k pure numbers


# Step 5: Combine everything
english_words = lower_words + upper_words + capitalized_words + mixed_words_english + pure_numbers
random.shuffle(english_words)  # Shuffle the final dataset

english_word_pattern = re.compile(r'^[a-zA-Z]+$')
all_words = top_n_list('ja', 1000000)

filtered_words = [word for word in all_words if len(word) >=3]
print(len(filtered_words))
japanese_word = [word for word in filtered_words if not english_word_pattern.match(word)]
japanese_words = japanese_word[:4000]
mix_base_words = japanese_word[4000:4500]
mixed_words_japanese = []
for word in mix_base_words:
    number = str(random.randint(10, 9999))
    if random.random() < 0.5:
        mixed_words_japanese.append(word + " " + number)
    else:
        mixed_words_japanese.append(number + " " + word)


japanese_words += pure_numbers + mixed_words_japanese
print(len(japanese_words))
print(japanese_words)

languages = ['English','Japanese','Hindi']
language_words = {
    'English': english_words,
    'Japanese': japanese_words,
    'Hindi': hindi_words
}


def to_pil(cv2_img):
    return Image.fromarray(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB))

def to_cv2(pil_img):
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

def apply_noise(image, noise_type):
    if image is None:
        print(f"Warning: Could not read image. Skipping noise type: {noise_type}")
        return None

    pil_img = to_pil(image)
    cv2_img = image.copy()
    h, w = cv2_img.shape[:2]

    if noise_type == "blur":
        return cv2.GaussianBlur(cv2_img, (3, 3), 0)  # reduced from (5,5)

    elif noise_type == "motion blur":
        kernel = np.zeros((9, 9))                   # reduced from (15,15)
        kernel[4, :] = np.ones(9)
        kernel /= 9
        return cv2.filter2D(cv2_img, -1, kernel)

    #chaange denominator for changing its max effect
    elif noise_type == "pixelation":
        h, w = cv2_img.shape[:2]
        temp = cv2.resize(cv2_img, (w//12, h//12), interpolation=cv2.INTER_LINEAR)  # less downscaling
        return cv2.resize(temp, (w, h), interpolation=cv2.INTER_NEAREST)


    elif noise_type == "compression artifacts":
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 10]
        _, enc_img = cv2.imencode('.jpg', cv2_img, encode_param)
        return cv2.imdecode(enc_img, 1)

    elif noise_type == "Gaussian noise":
        row, col, ch = cv2_img.shape
        mean = 0
        sigma = 35
        gauss = np.random.normal(mean, sigma, (row, col, ch))
        gauss = np.clip(gauss, -sigma*3, sigma*3)
        noisy_img = cv2_img.astype(np.float32) + gauss
        noisy_img = np.clip(noisy_img, 0, 255).astype(np.uint8)
        return noisy_img

    elif noise_type == "low resolution":
        small = cv2.resize(cv2_img, (32, 32), interpolation=cv2.INTER_LINEAR)
        return cv2.resize(small, (cv2_img.shape[1], cv2_img.shape[0]), interpolation=cv2.INTER_NEAREST)

    elif noise_type == "defocus blur":
        return cv2.GaussianBlur(cv2_img, (21, 21), 0)

    elif noise_type == "ringing artifacts":
        blurred = cv2.GaussianBlur(cv2_img, (0, 0), 3)
        return cv2.addWeighted(cv2_img, 1.5, blurred, -0.5, 0)

    elif noise_type == "lighting variations":
        enhancer = ImageEnhance.Brightness(pil_img)
        return to_cv2(enhancer.enhance(random.uniform(0.5, 1.5)))

    elif noise_type == "uneven illumination":
        h, w = cv2_img.shape[:2]
        mask = np.zeros((h, w), np.uint8)
        radius = w // 4  # Smaller radius for smaller illuminated area
        cv2.circle(mask, (w // 3, h // 3), radius, 255, -1)
        mask_3_channel = cv2.merge([mask]*3)
        return cv2.addWeighted(cv2_img, 1, mask_3_channel, 0.3, 0)



    elif noise_type == "glare":
        glare = np.zeros_like(cv2_img)
        center = (random.randint(0, w), random.randint(0, h))
        radius = random.randint(50, 100)
        cv2.circle(glare, center, radius, (180, 180, 180), -1)  # Less bright glare
        return cv2.addWeighted(cv2_img, 0.7, glare, 0.3, 0)


    elif noise_type == "underexposure":
        return cv2.convertScaleAbs(cv2_img, alpha=0.5, beta=-50)



    elif noise_type == "ambient noise":
        ambient = cv2.GaussianBlur(cv2_img, (15, 15), 20)  # Bigger kernel and higher sigma
        return cv2.addWeighted(cv2_img, 0.6, ambient, 0.4, 0)  # More blurred image weight


    elif noise_type == "perspective distortion":
        pts1 = np.float32([[0,0], [w,0], [0,h], [w,h]])
        pts2 = np.float32([[random.randint(0, w//10), random.randint(0, h//10)],
                           [w-random.randint(0, w//10), random.randint(0, h//10)],
                           [random.randint(0, w//10), h-random.randint(0, h//10)],
                           [w-random.randint(0, w//10), h-random.randint(0, h//10)]])
        M = cv2.getPerspectiveTransform(pts1, pts2)
        return cv2.warpPerspective(cv2_img, M, (w, h))

    elif noise_type == "fading":
        alpha = np.linspace(1, 0.05, w)
        mask = np.tile(alpha, (h, 1))
        return (cv2_img * mask[:, :, np.newaxis]).astype(np.uint8)

    elif noise_type == "ink bleed-through":
        flipped = cv2.flip(cv2_img, 1)
        blended = cv2.addWeighted(cv2_img, 0.8, flipped, 0.2, 0)
        return blended

    elif noise_type == "text smearing":
        kernel = np.ones((1, 6), np.uint8)
        return cv2.dilate(cv2_img, kernel, iterations=2)  # 2 iterations with smaller kernel = moderate effect

    elif noise_type == "stroke breaks":
        # Create a mask with mostly 1s and few 0s to reduce stroke break intensity
        prob = 0.92  # 95% chance of keeping pixels, 5% break
        mask = (np.random.rand(h, w, 1) < prob).astype(np.uint8)
        mask_3_channel = cv2.merge([mask[:, :, 0]] * 3)
        return cv2_img * mask_3_channel

    elif noise_type == "partial occlusion":
        noisy_img = cv2_img.copy()
        for _ in range(2):
            x1, y1 = random.randint(0, max(0, w-50)), random.randint(0, max(0, h-50))
            x2, y2 = x1 + random.randint(20, 35), y1 + random.randint(20, 35)
            cv2.rectangle(noisy_img, (x1, y1), (x2, y2), (0, 0, 0), -1)
        return noisy_img

    # change from 2,2 to 3,3
    elif noise_type == "font erosion":
      kernel = np.ones((3, 3), np.uint8)  # Bigger kernel for stronger erosion
      return cv2.erode(cv2_img, kernel, iterations=2)  # More aggressive


    elif noise_type == "character merging":
        # Choose between min and max effect kernels
        kernels = [np.ones((2, 2), np.uint8), np.ones((3, 3), np.uint8)]
        iterations_options = [1, 2]

        kernel = random.choice(kernels)
        iterations = random.choice(iterations_options)

        # To increase min effect and decrease max effect, limit the max to (3,3) kernel and 2 iterations
        return cv2.dilate(cv2_img, kernel, iterations=iterations)

    elif noise_type == "JPEG compression":
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 5]
        _, enc_img = cv2.imencode('.jpg', cv2_img, encode_param)
        decoded_img = cv2.imdecode(enc_img, cv2.IMREAD_COLOR)
        return decoded_img if decoded_img is not None else cv2_img

    elif noise_type == "color space mismatch":
        return cv2.cvtColor(cv2_img, cv2.COLOR_BGR2HSV)

    elif noise_type == "resolution scaling":
        small = cv2.resize(cv2_img, (w//2, h//2), interpolation=cv2.INTER_LINEAR)
        return cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)


    elif noise_type == "aliasing":
        small = cv2.resize(cv2_img, (w//3, h//3), interpolation=cv2.INTER_LINEAR)
        return cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)
    # chnaged 2  to 3 in denominator
    elif noise_type == "banding":
        banded = cv2_img.copy()
        for i in range(0, h, 20):
            start_row = i
            end_row = min(i + 5, h)
            banded[start_row:end_row] = banded[start_row:end_row] // 3
        return banded

    elif noise_type == "scan line artifacts":
        scan_img = cv2_img.copy()
        for i in range(0, h, 5):
             start_row = i
             end_row = min(i + 1, h)
             scan_img[start_row:end_row] = scan_img[start_row:end_row] // 3
        return scan_img
    # increased intensity
    elif noise_type == "scanner streaks":
      streak = cv2_img.copy()
      for _ in range(12):  # More streaks
          x = random.randint(0, w - 3)
          color = [random.randint(0, 255) for _ in range(3)]
          streak[:, x:x+2] = color  # Wider streak (2 px)
      return streak
    # changed
    elif noise_type == "printer toner gaps":
      toner = cv2_img.copy()
      center = h // 2
      for _ in range(3):
          offset = random.randint(-30, 30)  # Gap range near center
          y = np.clip(center + offset, 0, max(0, h - 5))  # Ensure within bounds
          toner[y:y+5, :] = [255, 255, 255]  # White horizontal gap
      return toner


  
    # changed
    elif noise_type == "paper texture interference":
      noise = np.random.normal(127, 50, cv2_img.shape).astype(np.uint8)  # Higher contrast noise
      return cv2.addWeighted(cv2_img, 0.7, noise, 0.3, 0)  # Stronger blend of noise


    elif noise_type == "multi-layer noise":
        noisy = apply_noise(cv2_img, "Gaussian noise")
        if noisy is not None:
          noisy = apply_noise(noisy, "text smearing")
        if noisy is not None:
          return apply_noise(noisy, "JPEG compression")
        return cv2_img
    # maked it more visible and darker
    elif noise_type == "watermarks":
      font_scale = max(1.5, h / 50)
      thickness = max(2, w // 150)
      watermark = cv2.putText(cv2_img.copy(), "IIT-J", (w // 4, h // 2),
                              cv2.FONT_HERSHEY_SIMPLEX, font_scale, (80, 80, 80), thickness, cv2.LINE_AA)
      return cv2.addWeighted(cv2_img, 0.75, watermark, 0.25, 0)  # Heavier watermark blend


    # elif noise_type == "overlay interference":
    #     overlay = np.full_like(cv2_img, 100)
    #     return cv2.addWeighted(cv2_img, 0.75, overlay, 0.25, 0)

    if noise_type == "salt and pepper":
        prob = 0.01  # Increased from 0.01 to 0.05
        noisy = cv2_img.copy()
        black = np.random.rand(h, w) < prob
        white = np.random.rand(h, w) < prob
        noisy[black] = 0
        noisy[white] = 255
        return noisy

    # increased its wffect
    elif noise_type == "ink spread":
        kernel = np.ones((3, 3), np.uint8)  # Bigger kernel for more spread
        return cv2.dilate(cv2_img, kernel, iterations=1)  # More iterations

    elif noise_type == "horizontal tear":
        y = random.randint(h // 3, 2 * h // 3)
        cv2.line(cv2_img, (0, y), (w, y), (255, 255, 255), thickness=7)
        return cv2_img

    elif noise_type == "vertical tear":
        x = random.randint(w // 3, 2 * w // 3)
        cv2.line(cv2_img, (x, 0), (x, h), (255, 255, 255), thickness=7)
        return cv2_img

    elif noise_type == "smudge":
        smudge_kernel = (9, 9)
        smudged = cv2.blur(cv2_img, smudge_kernel)
        return cv2.addWeighted(cv2_img, 0.6, smudged, 0.4, 0)

    elif noise_type == "text ghosting":
        shifted = np.roll(cv2_img, 5, axis=1)
        return cv2.addWeighted(cv2_img, 0.7, shifted, 0.3, 0)

    elif noise_type == "double scan":
        shifted = np.roll(cv2_img, random.randint(2, 6), axis=0)
        return cv2.addWeighted(cv2_img, 0.5, shifted, 0.5, 0)

    elif noise_type == "wave distortion":
        distorted = np.zeros_like(cv2_img)
        for i in range(h):
            offset = int(10.0 * np.sin(2 * np.pi * i / 60))
            distorted[i] = np.roll(cv2_img[i], offset, axis=1)
        return distorted

    # elif noise_type == "chromatic aberration":
    #     b, g, r = cv2.split(cv2_img)
    #     b = np.roll(b, 1, axis=1)
    #     r = np.roll(r, -1, axis=1)
    #     return cv2.merge([b, g, r])

    elif noise_type == "paper curl":
        mask = np.zeros((h, w), dtype=np.uint8)
        cv2.rectangle(mask, (0, 0), (w, h), 255, thickness=30)
        darken = cv2.merge([mask // 3] * 3)
        return cv2.subtract(cv2_img, darken)

    elif noise_type == "random scratches":
        scratched = cv2_img.copy()
        h, w = scratched.shape[:2]
        for _ in range(random.randint(3, 8)):
            x1 = random.randint(0, w)
            y1 = random.randint(0, h)
            x2 = x1 + random.randint(-w//2, w//2)
            y2 = y1 + random.randint(-h//2, h//2)
            color = (255, 255, 255) if random.random() < 0.5 else (0, 0, 0)
            thickness = random.randint(1, 2)
            cv2.line(scratched, (x1, y1), (x2, y2), color, thickness)
        return scratched

    elif noise_type == "scribble":
        scribbled = cv2_img.copy()
        h, w = scribbled.shape[:2]
        for _ in range(random.randint(1, 3)):
            points = np.array([
                [random.randint(0, w), random.randint(0, h)]
                for _ in range(random.randint(4, 7))
            ], np.int32).reshape((-1, 1, 2))
            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
            thickness = random.randint(1, 2)
            cv2.polylines(scribbled, [points], False, color, thickness, cv2.LINE_AA)
        return scribbled

    elif noise_type == "staple holes":
      noisy_img = cv2_img.copy()
      h, w = noisy_img.shape[:2]

      num_holes = random.randint(4, 10)
      radius = random.randint(5, 10)

      for _ in range(num_holes):
          position = random.choice([
              (random.randint(0, w//10), random.randint(0, h//10)),                  # top-left
              (random.randint(0, w//10), random.randint(h*9//10, h - 1)),            # bottom-left
              (random.randint(w*9//10, w - 1), random.randint(0, h//10)),            # top-right
              (random.randint(w*9//10, w - 1), random.randint(h*9//10, h - 1)),      # bottom-right
              (random.randint(0, w//10), random.randint(h//3, h*2//3)),              # middle-left
              (random.randint(w*9//10, w - 1), random.randint(h//3, h*2//3))         # middle-right
          ])
          cv2.circle(noisy_img, position, radius, (0, 0, 0), -1)

      return noisy_img
    elif noise_type == "water damage":
      h, w = image.shape[:2]
      blurred = cv2.blur(image, (6, 6))
      mask = np.zeros((h, w), dtype=np.uint8)

      num_spots = 2  # Number of damage spots
      for _ in range(num_spots):
          center = (random.randint(0, w), random.randint(0, h))
          radius = random.randint(30, 60)
          cv2.circle(mask, center, radius, 255, -1)

      mask_3ch = cv2.merge([mask]*3)
      return np.where(mask_3ch == 255, blurred, image)

    elif noise_type == "angled line":
      h, w = image.shape[:2]
      noisy_img = image.copy()

      color = (255, 255, 255) if random.random() > 0.5 else (0, 0, 0)
      thickness = 10

      angle = random.uniform(0, 180)
      radians = np.deg2rad(angle)

      # Compute line endpoints so it crosses the image fully
      x0 = int(w / 2 - w * np.cos(radians))
      y0 = int(h / 2 - w * np.sin(radians))
      x1 = int(w / 2 + w * np.cos(radians))
      y1 = int(h / 2 + w * np.sin(radians))

      cv2.line(noisy_img, (x0, y0), (x1, y1), color, thickness)

      return noisy_img
    elif noise_type == "random_erasure":
      h, w = image.shape[:2]
      output = image.copy()
      max_rect = 4;
      num_boxes = random.randint(2,4)  # Always at least 3 boxes

      for _ in range(num_boxes):
          x1 = random.randint(0, max(0, w - 10))
          y1 = random.randint(0, max(0, h - 10))

          box_width = random.randint(7, max(8, w // 5))
          box_height = random.randint(5, max(6, h // 4))

          x2 = min(w, x1 + box_width)
          y2 = min(h, y1 + box_height)

          # Randomly choose color: black or white
          color = 0 if random.random() < 0.5 else 255
          output[y1:y2, x1:x2] = color

      return output

    else:
        return cv2_img

implemented_noise_types = [
    "blur", "motion blur", "pixelation", "compression artifacts", "Gaussian noise",
    "low resolution",  "defocus blur", "uneven illumination",
    "glare", "underexposure", "ambient noise",
    "perspective distortion", "fading", "ink bleed-through", "text smearing",
    "stroke breaks", "partial occlusion", "character merging",
    "JPEG compression", "color space mismatch", "resolution scaling",
    "aliasing", "banding", "scan line artifacts", "scanner streaks",
    "printer toner gaps", "paper texture interference", "multi-layer noise", "watermarks",
    "salt and pepper", "ink spread", "horizontal tear", "vertical tear",
    "smudge", "text ghosting", "double scan", "wave distortion", "paper curl"
]
type1 = [
    "partial occlusion",
    "horizontal tear",
    "vertical tear",
    "scanner streaks",
    "printer toner gaps",
    # "smudge",
    "stroke breaks",
    # "cutout",
    "double scan",
    "scribble",
    "random scratches",
    "staple holes",
    "water damage",
    "random_erasure",
    "angled line"
]
type2 = [
    "",
    "perspective distortion",
    # "fading",
    "text ghosting",
    "wave distortion",
    "paper curl",
    # "multi-layer noise"
    "watermarks",
    "ink bleed-through",
    "color space mismatch",
    "resolution scaling"
] #nore about transformations
type3 = [
    "",
    "blur",
    # "motion blur",
    # "pixelation",
    "compression artifacts",
    "Gaussian noise",
    # "low resolution",
    # "defocus blur",
    "uneven illumination",
    "glare",
    # "underexposure",
    "ambient noise",
    "aliasing",
    "banding",
    "scan line artifacts",
    "paper texture interference",
    "salt and pepper",
    "ink spread",
    "character merging",
    "JPEG compression"
]# basic noises like wheather and real life

light_colors = [
    "white", "lightgray", "silver", "gainsboro", "whitesmoke", "beige",
    "seashell", "ivory", "lightyellow",  # removed 'lightgoldenrodyellow'
    "lightcyan", "lavender", "honeydew", "mintcream", "aliceblue",
    "mistyrose", "linen", "peachpuff", "palegoldenrod",
    "lightblue", "lightgreen", "powderblue", "skyblue", "paleturquoise"
]
dark_colors = [
    "black", "dimgray", "gray", "slategray", "darkslategray",
    "navy", "darkblue", "midnightblue", "darkgreen", "forestgreen",
    "darkolivegreen", "darkseagreen", "teal", "darkcyan", "maroon",
    "brown", "firebrick", "darkred", "purple", "indigo",
    "saddlebrown", "chocolate", "olive", "steelblue"
    # removed "darkmagenta"
]
import random

def get_text_background_pair():
    if random.random() < 0.5:
        text_color = random.choice(dark_colors)
        background_color = random.choice(light_colors)
    else:
        text_color = random.choice(light_colors)
        background_color = random.choice(dark_colors)
    return text_color, background_color



import cv2
import numpy as np

def generate_mask(clean_img, noisy_img):
    # Resize noisy image to match clean image dimensions (if needed)
    if clean_img.shape != noisy_img.shape:
        noisy_img = cv2.resize(noisy_img, (clean_img.shape[1], clean_img.shape[0]))
        # If clean_img is color and noisy_img is grayscale, convert noisy_img to color
        if len(clean_img.shape) == 3 and len(noisy_img.shape) == 2:
            noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_GRAY2BGR)
        elif len(clean_img.shape) == 2 and len(noisy_img.shape) == 3:
            clean_img = cv2.cvtColor(clean_img, cv2.COLOR_GRAY2BGR)

    diff = cv2.absdiff(clean_img, noisy_img)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)

    _, mask = cv2.threshold(gray, 25, 255, cv2.THRESH_BINARY)

    # Convert single-channel binary mask to RGB
    mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
    return mask_rgb



def generate_corrupted_segmentation_mask(clean_mask, noisy_mask):
    """
    Generates a corrupted segmentation mask where:
    - White text from clean mask is preserved.
    - Noise regions from noisy mask are suppressed (turned black).

    Args:
        clean_mask (np.ndarray): Binary mask (255 for text, 0 for background)
        noisy_mask (np.ndarray): Binary mask (255 for noise, 0 elsewhere)

    Returns:
        np.ndarray or None: Corrupted segmentation mask or None on failure.
    """
    if clean_mask is None or noisy_mask is None:
        print("❌ One or both masks are None.")
        return None

    if clean_mask.shape != noisy_mask.shape:
        print("❌ Masks have different shapes.")
        return None

    # Invert noisy mask so that noise becomes 0 (black)
    inverse_noisy_mask = cv2.bitwise_not(noisy_mask)

    # Apply bitwise AND to keep only clean text, remove noisy pixels
    corrupted_mask = cv2.bitwise_and(clean_mask, inverse_noisy_mask)

    return corrupted_mask

metadata = []
def generate_perfectly_cropped_image(
    text, font_path, output_path, ism_output_path,
    font_size=64, text_color="black", bg_color="white", padding=4
):
    try:
        font = ImageFont.truetype(font_path, font_size)
    except Exception as e:
        print("⚠ Font load error:", e)
        return False, 0

    # Compute tight bounding box
    dummy_img = Image.new("L", (1, 1))
    draw = ImageDraw.Draw(dummy_img)
    bbox = draw.textbbox((0, 0), text, font=font)
    if bbox is None:
        print(f"⚠ No visible text: {text}")
        return False, 0

    x0, y0, x1, y1 = bbox
    width = x1 - x0 + 2 * padding
    height = y1 - y0 + 2 * padding
    offset = (padding - x0, padding - y0)

    # Create clean RGB image
    clean_img = Image.new("RGB", (width, height), color=bg_color)
    draw_clean = ImageDraw.Draw(clean_img)
    draw_clean.text(offset, text, font=font, fill=text_color)

    # Create ISM image (white text on black)
    ism_img = Image.new("RGB", (width, height), color="black")
    draw_ism = ImageDraw.Draw(ism_img)
    draw_ism.text(offset, text, font=font, fill="white")

    rotation_angle = 0
    if random.random() < 0.3:
        rotation_angle = random.randint(-20, 20)
        # Convert to RGBA for rotation with transparency
        clean_img = clean_img.convert("RGBA")
        ism_img = ism_img.convert("RGBA")

        clean_img = clean_img.rotate(rotation_angle, expand=True, fillcolor=bg_color)
        ism_img = ism_img.rotate(rotation_angle, expand=True, fillcolor="black")

        # Crop to content using alpha
        bbox = clean_img.split()[-1].getbbox()
        if bbox:
            clean_img = clean_img.crop(bbox).convert("RGB")
            ism_img = ism_img.crop(bbox).convert("RGB")
        else:
            clean_img = clean_img.convert("RGB")
            ism_img = ism_img.convert("RGB")
    else:
        # Ensure both are RGB if no rotation
        clean_img = clean_img.convert("RGB")
        ism_img = ism_img.convert("RGB")

    # Save both images
    clean_img.save(output_path)
    ism_img.save(ism_output_path)

    print(f"✅ Saved: {output_path}, {ism_output_path} | rot: {rotation_angle}")
    return True, rotation_angle





def generate_dataset_pil(
    phrases,
    fonts_dir,
    clean_output_dir,
    noisy_output_dir,
    bitmask_output_dir,
    ISM_output_dir,
    CSM_output_dir,
    language,
    samples_per_phrase=20,
    font_size_range=(40, 120),
    text_colors=["black", "red", "blue"],
    bg_color="white"
):
    font_family_dirs = [d for d in Path(fonts_dir).iterdir() if d.is_dir()]
    if not font_family_dirs:
        raise ValueError("No font family directories found!")

    def get_random_font_path():
        random_family = random.choice(font_family_dirs)
        font_files = list(random_family.rglob("*.ttf")) + list(random_family.rglob("*.otf"))
        if not font_files:
            raise ValueError(f"No font files in {random_family}")
        return str(random.choice(font_files)), random_family.name




    cnt = 0

    for phrase in phrases:
        phrase_slug = phrase.replace(" ", "_")
        for i in range(samples_per_phrase):
            sample_id = f"{cnt:03d}"
            clean_path = os.path.join(clean_output_dir, f"{sample_id}_clean.png")

            bitmask_path = os.path.join(bitmask_output_dir, f"{sample_id}_mask.png")
            ISM_path=os.path.join(ISM_output_dir, f"{sample_id}_ism.png")
            CSM_path=os.path.join(CSM_output_dir, f"{sample_id}_CSM.png")


            font_path, font_family = get_random_font_path()

            font_size = random.randint(*sorted(font_size_range))
            text_color, bg_color = get_text_background_pair()
            # print("hello 0")
            # Step 1: Generate clean image with PIL
            success,rotation_angle = generate_perfectly_cropped_image(
                text=phrase,
                font_path=font_path,
                output_path=clean_path,
                ism_output_path=ISM_path,
                font_size=font_size,
                text_color=text_color,
                bg_color=bg_color

            )
            if not success:
                continue
            # print("hello 1")

            image = cv2.imread(clean_path)
            ISM_image = cv2.imread(ISM_path)
            # print("hello 2")
            if image is None:
                print(f"❌ Failed to load image: {clean_path}")
                continue

            # print("herllo")


            rotation_angle = 0


            # Apply Type 1 noise (restoration mask-worthy)
            type1_noise = random.choice(type1)
            noisy_img = apply_noise(image, type1_noise)



            # Step 3: Generate bitmask
            mask = generate_mask(image, noisy_img)
            cv2.imwrite(bitmask_path, mask)
            CSM_image = generate_corrupted_segmentation_mask(ISM_image, mask)
            cv2.imwrite(CSM_path, CSM_image)



            rand_val = random.random()  # between 0 and 1
            type2_noise = ""
            type3_noise = ""
            # Initialize noise tracking
            applied_noises = [type1_noise]

            if rand_val < 0.3:
            # Type 1 + Type 2
                type2_noise = random.choice(type2)
                noisy_img = apply_noise(noisy_img, type2_noise)
                applied_noises.append(type2_noise)

            elif rand_val < 0.6:
                # Type 1 + Type 3 (filter out aliasing & jpeg compression)
                type3_noise = random.choice(type3)
                noisy_img = apply_noise(noisy_img, type3_noise)
                applied_noises.append(type3_noise)

            elif rand_val < 0.85:
                # Type 1 + Type 2 + Type 3 (filter type3)
                type2_noise = random.choice(type2)
                noisy_img = apply_noise(noisy_img, type2_noise)
                applied_noises.append(type2_noise)

                type3_valid = [n for n in type3 if n not in {'aliasing', 'jpeg compression'}]
                type3_noise = random.choice(type3_valid)
                noisy_img = apply_noise(noisy_img, type3_noise)

                applied_noises.append(type3_noise)


            

            # Step 5: Save final noisy image
            noise_suffix = f"layer1_{type1_noise}"
            if type2_noise:
                noise_suffix += f"_layer2_{type2_noise}"
            if type3_noise:
                noise_suffix += f"_layer3_{type3_noise}"

            noisy_path = os.path.join(noisy_dir, f"{sample_id}_noisy_{noise_suffix}.png")
            cv2.imwrite(noisy_path, noisy_img)
            if phrase in lower_words:
                word_type = "lower"
            elif phrase in upper_words:
                word_type = "upper"
            elif phrase in capitalized_words:
                word_type = "capitalized"
            elif phrase in mixed_words_hindi:
                word_type = "mixed"
            elif phrase in mixed_words_japanese:
                word_type = "mixed"
            elif phrase in mixed_words_english:
                word_type = "mixed"
            elif phrase in pure_numbers:
                word_type = "pure_number"
            else:
                word_type = "normal"

            # Step 6: Save metadata
            metadata.append({
                "code":f"{cnt:05d}",
                "word": phrase,
                "language": language,
                "word_type":word_type,
                "text_color": text_color,
                "background_color": bg_color,
                "font_size": font_size,
                "font_family": font_family,
                "font_style": Path(font_path).stem.replace(" ","_").split("_")[0],
                "font_path": font_path,
                "noise_type1": type1_noise,
                "noise_type2": type2_noise,
                "noise_type3": type3_noise,
                "angle": rotation_angle,
                "clean_path": clean_path,
                "noisy_path": noisy_path,
                "binary_mask_path": bitmask_path
            })

            print(f"✅ {sample_id} done with {noise_suffix} | rot: {rotation_angle}")
            cnt += 1

    # Step 7: Save metadata



for lang in languages:
    fonts_dir = f"/DATA1/ocrteam/word_restoration/reconstruction/datasets/fonts/{lang}"  # Upload fonts here
    
    output_root = f'/DATA1/ocrteam/word_restoration/reconstruction/data/{lang}_sample_dataset'
    clean_dir = os.path.join(output_root, 'clean')
    noisy_dir = os.path.join(output_root, 'noisy')
    bitmask_dir = os.path.join(output_root, 'bitmask')
    ISM_dir = os.path.join(output_root, 'Intact Segment Mask')
    CSM_dir=os.path.join(output_root, 'Corrupted Segment Mask')
    os.makedirs(clean_dir, exist_ok=True)
    os.makedirs(noisy_dir, exist_ok=True)
    os.makedirs(bitmask_dir, exist_ok=True)
    os.makedirs(ISM_dir, exist_ok=True)
    os.makedirs(CSM_dir, exist_ok=True)
    generate_dataset_pil(
        language_words[lang], 
        fonts_dir, 
        clean_output_dir=clean_dir,
        noisy_output_dir=noisy_dir,
        bitmask_output_dir=bitmask_dir,
        ISM_output_dir=ISM_dir,
        CSM_output_dir=CSM_dir,
        language=lang,
        samples_per_phrase=1
        )


output_root_csv = '/DATA1/ocrteam/word_restoration/reconstruction/data'
metadata_csv_path = os.path.join(output_root_csv, "metadata.csv")
df = pd.DataFrame(metadata)
df.to_csv(metadata_csv_path, index=False)
print(f"📄 Metadata saved to {metadata_csv_path}")